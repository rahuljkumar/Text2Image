{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFezCehR1Le4OWkpYnxaCF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahuljkumar/Text2Image/blob/main/Text2Image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rl-e4ooxoVNe"
      },
      "outputs": [],
      "source": [
        "!pip install transformers diffusers #Installing Transformers and Diffusers to use pre-trained models from Huggingface"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing necessary libraries\n",
        "import diffusers\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import torch"
      ],
      "metadata": {
        "id": "ssGQLUfeom5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"emilianJR/epiCRealism\" #Defining the pre-trained model name from Huggingface\n",
        "\n",
        "#Uncomment the below line and commment the above line to choose a different model\n",
        "#model_id = \"digiplay/NextPhoto_v1\"\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16) #Loading the pre-trained model and creating a pipeline\n",
        "\n",
        "#Comment the above line and uncomment the below line if you face CUDA out of memory error\n",
        "#pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16, max_split_size_mb=256)\n",
        "\n",
        "pipe = pipe.to(\"cuda\") #Move the pipeline to GPU for faster processing\n",
        "\n",
        "#Uncomment the below line if any CUDA out of memory error pops up\n",
        "#pipe.enable_attention_slicing()\n",
        "\n",
        "#Defining the positive prompt, describing the desired attributes of the generated image\n",
        "prompt = \"photorealistic, Indian woman infront of the Taj Mahal, black dress, natural hair, looking straight, looking forward, brightly lit, clear face, standing against a wall, middle-aged, detailed skin texture, great hair texture, realistic texture of clothing, RAW photo, subject, bright lighting, high quality, film grain, brown hair, long hair, human like, sharp\"\n",
        "\n",
        "#Defining the negative prompt, listing undesired attributes to avoid in the generated image\n",
        "neg_prompt = \"shadow, bad anatomy, bad hands, three hands, three legs, bad arms, missing legs, missing arms, poorly drawn face, bad face, fused face, cloned face, worst face, three crus, extra crus, fused crus, worst feet, three feet, fused feet, fused thigh, three thigh, fused thigh, extra thigh, worst thigh, missing fingers, extra fingers, ugly fingers, long fingers, horn, extra eyes, huge eyes, 2girl, amputation, disconnected limbs, cartoon, cg, 3d, unreal, animate, anime, cartoony, blurred, disfigured\"\n",
        "\n",
        "image = pipe(prompt, negative_prompt=neg_prompt).images[0] #Generating an image using the prompts and the pipeline\n",
        "\n",
        "image.save(\"Generated_Image.png\") #Saving the image in png format"
      ],
      "metadata": {
        "id": "XQcMMl4fopGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/xinntao/Real-ESRGAN.git #Clone Real-ESRGAN repository from GitHub\n",
        "\n",
        "%cd Real-ESRGAN #Move into the cloned directory\n",
        "\n",
        "#Installing the dependent libraries\n",
        "!pip install basicsr\n",
        "!pip install facexlib\n",
        "!pip install gfpgan\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "!python setup.py develop #Setup the Real-ESRGAN environment for development\n",
        "\n",
        "# Download the pre-trained model\n",
        "!wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P experiments/pretrained_models\n",
        "\n",
        "#%cd .. #Move out of the Real-ESRGAN directory"
      ],
      "metadata": {
        "id": "RAj0YZVWtLtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%cd Real-ESRGAN\n",
        "\n",
        "#Importing the necessary libraries\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "#Define folder names for uploaded images and results\n",
        "upload_folder = 'upload'\n",
        "result_folder = 'results'\n",
        "\n",
        "if os.path.isdir(upload_folder):\n",
        "    shutil.rmtree(upload_folder) #If the upload folder exists, remove it\n",
        "if os.path.isdir(result_folder):\n",
        "    shutil.rmtree(result_folder) #If the result folder exists, remove it\n",
        "os.mkdir(upload_folder) #Create a new upload folder\n",
        "os.mkdir(result_folder) #Create a new result folder\n",
        "\n",
        "image_path = \"/content/Generated_Image.png\" #Define the path to the image to be processed\n",
        "\n",
        "shutil.copy(image_path, upload_folder) #Copy the specified image to the upload folder\n",
        "\n",
        "#%cd .. #Change directory back to the parent directory"
      ],
      "metadata": {
        "id": "sXJeFOZktLpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%cd Real-ESRGAN\n",
        "\n",
        "#Run inference using Real-ESRGAN with the specified parameters:\n",
        "#-n: model name (RealESRGAN_x4plus)\n",
        "#-i: input directory containing images to be processed (upload)\n",
        "#--outscale: scale factor for output resolution (4)\n",
        "#--face_enhance: perform face enhancement during processing\n",
        "!python inference_realesrgan.py -n RealESRGAN_x4plus -i upload --outscale 4 --face_enhance\n",
        "\n",
        "%cd .."
      ],
      "metadata": {
        "id": "4SL73LxhtLmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the files module from the google.colab library, which enables file operations in Google Colab\n",
        "from google.colab import files\n",
        "\n",
        "#Get a list of filenames in the '/content/Real-ESRGAN/results' directory\n",
        "filename= os.listdir('/content/Real-ESRGAN/results')\n",
        "\n",
        "#Download the first file from the '/content/Real-ESRGAN/results/' directory\n",
        "files.download('/content/Real-ESRGAN/results/'+filename[0])"
      ],
      "metadata": {
        "id": "h4unlRWwtLiX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}